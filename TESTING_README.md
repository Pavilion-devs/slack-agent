# ğŸ§ª Testing Guide - Delve AI Support Agent

This guide explains how to test the improved LangChain-based RAG system using the provided testing tools.

## ğŸš€ Quick Start

### Prerequisites
1. **Ollama with llama3.2:3b model**:
   ```bash
   ollama serve
   ollama pull llama3.2:3b
   ```

2. **Virtual environment activated**:
   ```bash
   source venv/bin/activate
   ```

3. **Dependencies installed**:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“‹ Testing Options

### 1. ğŸ® Manual Interactive Testing
**Best for: Quick testing with your own questions**

```bash
python run_manual_test.py
```

**Features:**
- Interactive command-line interface
- Real-time question processing
- Detailed response analysis
- Framework detection validation
- Performance metrics

**Options:**
- Interactive Testing (ask your own questions)
- Predefined Test Cases (automated validation)

### 2. ğŸ“Š Web Dashboard Testing
**Best for: Visual testing and batch operations**

```bash
python run_dashboard.py
```

**Or alternatively:**
```bash
streamlit run src/simple_dashboard.py
```

**Features:**
- ğŸ§ª **Interactive Testing**: Web-based question interface
- ğŸ“Š **Batch Testing**: Run predefined test suites
- ğŸ¥ **System Health**: Monitor component status
- âš™ï¸ **Configuration**: View system settings
- ğŸ“– **Test Cases**: Reference documentation

### 3. ğŸ”¬ Unit Tests
**Best for: Automated validation**

```bash
python -m pytest tests/ -v
```

## ğŸ“ Test Cases

Comprehensive test cases are provided in `test_cases.md` covering:

### ğŸ¯ Core Categories
- **Basic Product Information** (high confidence, no escalation)
- **SOC2 Compliance** (high confidence, framework detection)
- **HIPAA Compliance** (high confidence, framework detection)
- **GDPR Compliance** (high confidence, framework detection)
- **ISO27001 Questions** (high confidence, framework detection)
- **Technical Configuration** (medium confidence)
- **Pricing & Sales** (medium confidence, possible escalation)
- **Demo Requests** (medium confidence, likely escalation)
- **Critical Issues** (any confidence, should escalate)
- **Out-of-Scope** (low confidence, should escalate)

### ğŸ“Š Expected Performance
- **Response Time**: < 30 seconds (< 15s excellent)
- **Confidence Scores**: 
  - High (â‰¥0.8): Should not escalate
  - Medium (0.6-0.79): Context-dependent
  - Low (<0.6): Should escalate
- **Framework Detection**: Accurate identification of SOC2, HIPAA, GDPR, ISO27001

## ğŸ” What to Test

### 1. Framework Detection
```
âœ… "How does SOC2 compliance work?" â†’ Should detect SOC2
âœ… "What are HIPAA requirements?" â†’ Should detect HIPAA
âœ… "Help with GDPR data rights" â†’ Should detect GDPR
âœ… "ISO27001 certification process" â†’ Should detect ISO27001
```

### 2. Confidence Scoring
```
âœ… "What is Delve?" â†’ High confidence (â‰¥0.8)
âœ… "How do I configure SSO?" â†’ Medium confidence (0.6-0.8)
âœ… "What is quantum computing?" â†’ Low confidence (<0.4)
```

### 3. Escalation Logic
```
âœ… Critical issues â†’ Always escalate
âœ… Out-of-scope questions â†’ Should escalate
âœ… Low confidence responses â†’ Should escalate
âœ… Well-covered topics â†’ Should not escalate
```

### 4. Response Quality
```
âœ… Relevant and accurate information
âœ… Proper source citations
âœ… Professional tone
âœ… Appropriate length
```

## ğŸ“ˆ Performance Benchmarks

### âš¡ Response Time Targets
- ğŸŸ¢ **Excellent**: < 15 seconds
- ğŸŸ¡ **Good**: 15-30 seconds
- ğŸ”´ **Needs Improvement**: > 30 seconds

### ğŸ¯ Accuracy Targets
- ğŸŸ¢ **Framework Detection**: > 90% accuracy
- ğŸŸ¢ **Confidence Scoring**: Appropriate for content
- ğŸŸ¢ **Escalation Logic**: > 90% appropriate decisions

## ğŸ› Troubleshooting

### Common Issues

1. **"RAG system failed to initialize"**
   ```bash
   # Check Ollama is running
   curl http://localhost:11434/api/tags
   
   # Restart Ollama if needed
   ollama serve
   ```

2. **Slow response times**
   - Check Ollama server load
   - Verify model is fully loaded
   - Restart Ollama service

3. **Low confidence scores**
   - Verify knowledge base is loaded
   - Check if question is in scope
   - Review RAG system initialization

4. **Import errors**
   ```bash
   # Reinstall dependencies
   pip install -r requirements.txt
   
   # Check virtual environment
   which python
   ```

## ğŸ“Š Sample Test Session

Here's what a typical test session looks like:

```
ğŸ¤” Your question: How does SOC2 compliance work with Delve?

ğŸ”„ Processing: How does SOC2 compliance work with Delve?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ“Š RESULTS:
   Agent: rag_agent
   Processing Time: 12.34s
   Confidence: 0.87
   Confidence Level: 0.87
âœ… No escalation needed
   Frameworks Detected: SOC2

ğŸ’¬ RESPONSE:
Delve helps organizations achieve SOC2 compliance by providing automated 
evidence collection, continuous monitoring, and comprehensive reporting 
for all five trust service criteria: Security, Availability, Processing 
Integrity, Confidentiality, and Privacy...

ğŸ“š SOURCES (3):
   1. ğŸ“– SOC2 Compliance Overview > Trust Service Criteria (SOC2)
   2. ğŸ“– Automated Evidence Collection > Continuous Monitoring (SOC2)
   3. ğŸ“– Compliance Reporting > SOC2 Type II Reports (SOC2)
```

## âœ… Test Results Template

Use this template to record your testing results:

```markdown
## Test Session - [Date]

### System Performance
- Average Response Time: ___s
- Tests Completed: ___/___
- Overall Pass Rate: ___%

### Framework Detection
- SOC2: ___/___
- HIPAA: ___/___  
- GDPR: ___/___
- ISO27001: ___/___

### Confidence Accuracy
- High Confidence Questions: ___/___
- Medium Confidence Questions: ___/___
- Low Confidence Questions: ___/___

### Escalation Logic
- Appropriate Escalations: ___/___
- Missed Critical Escalations: ___/___

### Issues Found
1. ___
2. ___

### Overall Assessment
Performance: â­â­â­â­â­ (1-5 stars)
Accuracy: â­â­â­â­â­ (1-5 stars)
```

## ğŸ¯ Testing Checklist

Before you start testing:
- [ ] Ollama is running (`ollama serve`)
- [ ] llama3.2:3b model is available (`ollama list`)
- [ ] Virtual environment is activated
- [ ] All dependencies are installed
- [ ] Choose your testing method (manual vs dashboard)

During testing:
- [ ] Test questions from each category
- [ ] Record response times
- [ ] Validate framework detection
- [ ] Check escalation decisions
- [ ] Note any issues or errors

After testing:
- [ ] Calculate performance metrics
- [ ] Document any issues found
- [ ] Share results for system improvement

Happy testing! ğŸš€